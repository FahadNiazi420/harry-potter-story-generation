{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QXhLR0AZIAO",
        "outputId": "d71db9ba-decf-41c6-c905-45e1b1f532c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in the current directory:\n",
            "['(Assignment 1 & 2)Regular Expression.docx.pdf', '2021cs14_quiz1.pdf', 'ASS12.docx', 'Assignment 4_Edit distance & Sequence Alignment.docx.pdf', 'Assignment1_2.ipynb', 'harrypotter.txt', 'harry_potter', 'HPGEN.ipynb', 'NLP_Slides', 'training_checkpoints', 'Tuning Transformer for Summary Generation T5.ipynb', '_(Assignment 3)Sentence Segmentation.docx.pdf']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"Files and folders in the current directory:\")\n",
        "print(os.listdir('.'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU6E_dboU-jH",
        "outputId": "2f887e17-6371-4e9f-b108-1cc67abf52f4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./harry_potter/1SorcerersStone.txt\n",
            "./harry_potter/2ChamberofSecrets.txt\n",
            "./harry_potter/3ThePrisonerOfAzkaban.txt\n",
            "./harry_potter/4TheGobletOfFire.txt\n",
            "./harry_potter/5OrderofthePhoenix.txt\n",
            "./harry_potter/6TheHalfBloodPrince.txt\n",
            "./harry_potter/7DeathlyHollows.txt\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('./harry_potter/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yG_n40gFzf9s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavnuByVymwK",
        "outputId": "2c2e2b31-4763-4088-a5ce-aee13ac74466",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'charmap' codec can't decode byte 0x90 in position 970493: character maps to <undefined>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[1;32m---> 12\u001b[0m       outfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mharrypotter.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength of text: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m characters\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(text)))\n",
            "File \u001b[1;32mc:\\Users\\HS TRADER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 970493: character maps to <undefined>"
          ]
        }
      ],
      "source": [
        "# Merge all Harry Potter books into a single file\n",
        "with open('harrypotter.txt', 'w', encoding='utf-8') as outfile:\n",
        "    for file in files:\n",
        "        with open(file, encoding='utf-8') as infile:\n",
        "            outfile.write(infile.read())\n",
        "\n",
        "# Read the merged text file\n",
        "with open('harrypotter.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f'Length of text: {len(text)} characters')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duhg9NrUymwO",
        "outputId": "10e0e6ed-2e88-4bb0-89e8-59b053737024",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Harry Potter and the Sorcerer's Stone \n",
            "\n",
            "CHAPTER ONE \n",
            "\n",
            "THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they \n"
          ]
        }
      ],
      "source": [
        "# Taking a look at the text\n",
        "print(text[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlCgQBRVymwR",
        "outputId": "d686780c-90fd-463e-8320-381034a1ca4a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IalZLbvOzf-F",
        "outputId": "18de03b8-8de8-449a-ddfc-598f00d7a73a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[39 64 81 ... 75 75 15]\n"
          ]
        }
      ],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2index = {u:i for i, u in enumerate(vocab)}\n",
        "index2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2index[c] for c in text])\n",
        "\n",
        "print(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VKcQHcymwb",
        "outputId": "3b5751b9-7117-42d0-bfb1-689aa2570a75",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Harry Potter ' -- characters mapped to int -- > [39 64 81 81 88  3 47 78 83 83 68 81  3]\n"
          ]
        }
      ],
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} -- characters mapped to int -- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UHJDA39zf-O",
        "outputId": "a3266d06-deab-4321-c21b-607b1aea9ba2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H\n",
            "a\n",
            "r\n",
            "r\n",
            "y\n"
          ]
        }
      ],
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "#sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(index2char[i.numpy()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4hkDU3i7ozi",
        "outputId": "1e5b6710-820b-4b75-f5ea-17d29165215f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Harry Potter and the Sorcerer's Stone \\n\\nCHAPTER ONE \\n\\nTHE BOY WHO LIVED \\n\\nMr. and Mrs. Dursley, of nu\"\n",
            "'mber four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They'\n",
            "\" were the last people you'd expect to be involved in anything strange or mysterious, because they jus\"\n",
            "\"t didn't hold with such nonsense. \\n\\nMr. Dursley was the director of a firm called Grunnings, which ma\"\n",
            "'de drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. '\n"
          ]
        }
      ],
      "source": [
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(index2char[item.numpy()])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9NGu-FkO_kYU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2pGotuNzf-S",
        "outputId": "263dc440-3351-4cc5-f41e-67d4fb627490",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G32026wrsi5f",
        "outputId": "a7655621-3fd2-4195-f0f5-4f8dfae37f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: (64, 100)\n",
            "Target shape: (64, 100)\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input shape:\", input_example.shape)\n",
        "    print(\"Target shape:\", target_example.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHT8cLh7EAsg",
        "outputId": "7acd7ed3-7140-480a-80fb-84fd958ddede",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106\n"
          ]
        }
      ],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 300 #256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units1 = 1024\n",
        "rnn_units2 = 1024\n",
        "rnn_units=[rnn_units1, rnn_units2]\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DiGEnqVQtoPf"
      },
      "outputs": [],
      "source": [
        "seq_length = 100  # Define sequence length explicitly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MtCrdfzEI2N0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size, seq_length):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Define the input layer with batch input shape\n",
        "        tf.keras.layers.InputLayer(batch_input_shape=(batch_size, seq_length)),\n",
        "\n",
        "        # Embedding layer\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "\n",
        "        # First GRU layer\n",
        "        tf.keras.layers.GRU(rnn_units[0],\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        # Second GRU layer\n",
        "        tf.keras.layers.GRU(rnn_units[1],\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        # Output layer\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wwsrpOik5zhv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "seq_length = 100  # Define your sequence length\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seq_length=seq_length\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "vPGmAAXmVLGC",
        "outputId": "cd4fb990-e9be-4f62-926b-64d796407aed",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,073,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,297,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">108,650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │          \u001b[38;5;34m31,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m4,073,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m6,297,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m106\u001b[0m)              │         \u001b[38;5;34m108,650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,511,522</span> (40.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,511,522\u001b[0m (40.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,511,522</span> (40.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,511,522\u001b[0m (40.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4HrXTACTdzY-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DDl1_Een6rL0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W6fWTriUZP-n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7yGBE2zxMMHs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "EPOCHS=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UK-hmKjYVoll",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zk2WJ2-XjkGz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "latest_check= tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1bXX64NmesM",
        "outputId": "1ddb5b91-fb24-46da-a179-e4e8a639ef76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ckpt_1.weights.h5']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(checkpoint_dir))\n",
        "\n",
        "# Manually assign the checkpoint file path\n",
        "latest_check = os.path.join(checkpoint_dir, 'ckpt_1.weights.h5')\n",
        "\n",
        "# Ensure the file exists\n",
        "if not os.path.exists(latest_check):\n",
        "    raise FileNotFoundError(f\"Checkpoint file not found: {latest_check}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LycQ-ot_jjyu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the weights into the model\n",
        "seq_length = 100\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1, seq_length=seq_length)\n",
        "\n",
        "# Check if the latest_check variable is not None before loading weights\n",
        "if latest_check is not None:\n",
        "    model.load_weights(latest_check)\n",
        "else:\n",
        "    print(\"No checkpoint file found. Starting with a fresh model.\")\n",
        "\n",
        "\n",
        "# Rebuild the model for inference\n",
        "#model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "71xa6jnYVrAN",
        "outputId": "145ba76b-7e5e-4943-bc04-8e90339e00d0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,073,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,297,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">108,650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m)               │          \u001b[38;5;34m31,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │       \u001b[38;5;34m4,073,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │       \u001b[38;5;34m6,297,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m106\u001b[0m)               │         \u001b[38;5;34m108,650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,511,522</span> (40.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,511,522\u001b[0m (40.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,511,522</span> (40.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,511,522\u001b[0m (40.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvIHEBJcrmej",
        "outputId": "f9d942e0-86ab-4f40-e862-97b8c130cd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 100)\n",
            "(64, 64, 100)\n"
          ]
        }
      ],
      "source": [
        "# Ensure dataset is correctly batched\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Calculate split index for training and testing\n",
        "split_index = int(0.8 * len(list(dataset)))\n",
        "test_dataset = dataset.skip(split_index)\n",
        "\n",
        "# Ensure the model is compiled\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Check shape of dataset before passing it into the model\n",
        "for example in test_dataset.take(1):\n",
        "    input_example, target_example = example\n",
        "    print(input_example.shape)  # Verify shape\n",
        "    print(target_example.shape)  # Verify shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJF6K2UawB76",
        "outputId": "42b67d18-b27e-49e5-8765-f630e9de604e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None, 64, 64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset = test_dataset.batch(1)\n",
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LOy8FhXqZBl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate the model on the test dataset\n",
        "evaluation_metrics = model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Loss: {evaluation_metrics[0]}\")\n",
        "print(f\"Accuracy: {evaluation_metrics[1]}\")\n",
        "\n",
        "# Plot the evaluation metrics\n",
        "metrics = ['Loss', 'Accuracy']\n",
        "values = evaluation_metrics\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(metrics, values, color=['blue', 'green'])\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WvuwZBX5Ogfd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Number of characters to generate\n",
        "    num_generate = 1000\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2index[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low results in more predictable text.\n",
        "    # Higher results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    scaling = 0.5  # 1\n",
        "\n",
        "    # Resetting the states of RNN layers\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.GRU):\n",
        "            layer.reset_states()\n",
        "\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # Remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / scaling\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(index2char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktovv0RFhrkn",
        "outputId": "3c3fb5cd-ed18-4fae-82ee-91394521f7f2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dumbledore was still painting the first time and falling in the castle and the only one who had been a birt of under Harry's head.\n",
            "\"I don't know what to do it.\"\n",
            "\"It was the one who were pointing to the grass and still still standing in the castle all the picture of the common room, and Hermione had been blacked in his hands, the stone still standing in sides, but Harry could not help the potion in the end of the sound of the fear of the castle, the stone steps and sund them to him to take a small black door.\n",
            "\"But I think the wizard said Ron gave a pair of sight behind him. \"I beg in the castle that many mirror. Harry said to see the silence that spend like many into the corner that he was important to tee the staircase with the tent to him to Harry.\n",
            "\"But what do you seen him - years ago,\" said Harry, his last sing in the same time the point in the end of the cold small blink and that where he had been concentrated in a few moments were still more than she had the snake of the castle with a tight \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Dumbledore \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOPtGumRU-jl",
        "outputId": "0080aa8e-590b-4685-e369-02041c364f7d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Harry killed Ron  standing as they left the tiny sides, and say Lily, the last little shock and still still still still still so far off it in front of the steps to the corner and still still with a small shoulders for a moment the common room. He had not seemed to him to see the marble still stormed in his back to the side of the same moment, the only sound of the castle was the only one who cleared behind him.\n",
            "\"Perhaps it did not in the corridor but he said, and he felt like the ground of the Prime Minister and the grass as he pulled out the family to make a man was a long time whispered in the door to the pain of the wall back and the many parchment, and she said impressive in his great seconds had a conversation had been closed his eyes in her hand. He could not remember in the door.\n",
            "\"Well, the first time you think you have to look at him to get the connection of the stone smoke and turned in the corner and hin in the face stand at the room and the door stood shaking his eyes with a mistake of the s\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Harry killed Ron  \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTV30QXAU-jm",
        "outputId": "49fd4bb9-e7b8-432b-840c-d8c4a357e5e6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Harry killed Ron  came to the corridor and his shoulder and feel that he had the goblin person her sleep and shook his face as he said, \"The Death Eater was still wearing its sides of the castle, and he was still still going to him that might have been before the marble and shook his face from the sofath time behind them in the head in a long time that was the shider of his face with him. He was still eyes from the gate and little high and this time they seemed to have a way back in the countryside of the pool and streaming out of the front of the Hallows -- \"\n",
            "\"I didn’t have to do it all this and tears to the curtains and inside the air again. He left him to discuss them a bit of back to him, like uncomfortable to the common room with a many place where he said, and the visit that it was not so on the exception that he was him and say in the castle with him that the man common room was silently so that his life could have to mention the steps to Harry Potterwatch with the battle black from his mind and \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Harry killed Ron  \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wok1eJrU-jm",
        "outputId": "1d02fc24-1e8f-4bc7-93c0-0dd9c66a20e7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hermoine Killed Snape  behind them as he said, and the goblin side him back, planning to him he had been relieved it open. The parchment of the sun. Harry said in a little silence. \"He did not leave the story side of the contrary, and Harry saw the bloodship was still standing at the sound of her of the windows and the same boy was leading Ron and Hermione came to his feet as they said, and where they were saying the stone still seemed to say Tonks had been like the sword to the first bed, and the brightened and took and said, \"This is it was a long time we've got a place where the common room with him to make a connection by the same time the man who was remembering a mistake. Harry said as they were still at the end of the garden pause. \"I don’t mind the curse that he was still to him, on the same minutes to him, but I think I leave the parchment to the same moment, the wand hold that had he had him to see them in the darkness and the swirling village remained into the desperate the family shook him for th\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Hermoine Killed Snape  \"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
